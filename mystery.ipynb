{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9v2TMhxpbb9Hk1LRzmePW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clashgamer123/SOC_Pytorch/blob/main/mystery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets develop a basic neural network and train it.\n",
        "We have a mystery function and the network should be able to imitate the function properly.\n",
        "Our Network will have one input layer containing 5 neurons and a single output neuron.There is also a hidden layer with 10 neurons."
      ],
      "metadata": {
        "id": "cItdGxfLaRaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "31h7EY5Vc1_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets define the mystery function and the network model."
      ],
      "metadata": {
        "id": "Keid1exTeBIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mystery(input):  # Input is a tensor containing 5 numbers.\n",
        "  output = input.std()\n",
        "  return torch.tensor(output)\n",
        "\n",
        "# Define the dependency of one layer on previous one.\n",
        "fc1 = nn.Linear(5, 10, dtype=torch.double)\n",
        "fc2 = nn.Linear(10, 1, dtype=torch.double)\n",
        "\n",
        "relu = nn.ReLU()\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(fc1, relu, fc2, sigmoid)  # Defined the model\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxsyv2KjeEyh",
        "outputId": "221a28d7-b662-410a-c69e-a6c7c52b76a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (3): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is to define the criterion for the loss function as well as\n",
        "The stochastic gradient descent to update weights and biases."
      ],
      "metadata": {
        "id": "Wn8oAXyHgxay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()  # Mean Square Error.\n",
        "optimizer = torch.optim.SGD(model.parameters() ,lr=0.01, momentum=0.9 ) # Defined the SGD optimizer"
      ],
      "metadata": {
        "id": "cG4W5QJQg_4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "WEMdNuUAh-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use a 1000 examples for training and also let the batch size be 10.\n",
        "batch_size = 20\n",
        "input_data_1 = torch.rand(5000, 5, dtype=torch.double)\n",
        "input_data_2 = torch.rand(5000, 5, dtype=torch.double)\n",
        "\n",
        "for epoch in range(500):\n",
        "  if epoch < 250:\n",
        "    input_batch = input_data_1[epoch*20:(epoch+1)*20, :]\n",
        "  else:\n",
        "    input_batch = input_data_2[(epoch-250)*20:(epoch-249)*20, :]\n",
        "\n",
        "  desired_output = []\n",
        "  for inp in input_batch:\n",
        "    outp = list(mystery(inp).unsqueeze(0))\n",
        "    desired_output.append(outp)\n",
        "  desired_output = torch.tensor(desired_output)\n",
        "\n",
        "  observed_output = model(input_batch)\n",
        "\n",
        "  loss = criterion(desired_output, observed_output)\n",
        "\n",
        "  # print a few losses\n",
        "  if epoch % 20 == 0:\n",
        "      print(f'Loss : {loss.item()}')\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()  # Fix typo\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU2jG4rEiEKx",
        "outputId": "55bf1c61-3f20-4616-8bf0-bd5c12f2c6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-7de48b09b13c>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(output)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 0.0038711793740109504\n",
            "Loss : 0.004813825709702081\n",
            "Loss : 0.0070308012533176634\n",
            "Loss : 0.009360977295303686\n",
            "Loss : 0.0040828729389849865\n",
            "Loss : 0.00416269572915221\n",
            "Loss : 0.006080850051748132\n",
            "Loss : 0.0031551181235145525\n",
            "Loss : 0.009102862929009812\n",
            "Loss : 0.005195832355390962\n",
            "Loss : 0.0035411441248521273\n",
            "Loss : 0.006721438118124425\n",
            "Loss : 0.006244887461407833\n",
            "Loss : 0.005070489864360266\n",
            "Loss : 0.004428795568860735\n",
            "Loss : 0.0042319370914031314\n",
            "Loss : 0.00827659446214434\n",
            "Loss : 0.007398447956427192\n",
            "Loss : 0.0056954951053255045\n",
            "Loss : 0.007348899814481761\n",
            "Loss : 0.0050196806538395505\n",
            "Loss : 0.0059644902502355825\n",
            "Loss : 0.002875182986766949\n",
            "Loss : 0.009065661812461141\n",
            "Loss : 0.0057716092103985645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets verify for some random array now."
      ],
      "metadata": {
        "id": "MxgAQGH15DkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input array\n",
        "arr = torch.tensor([0.1,0.2,0.4,0.7,0.7], dtype=torch.double)\n",
        "print(mystery(arr).item())\n",
        "output = model(arr)\n",
        "print(output.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvMh9CAc5JD6",
        "outputId": "ae74dcb4-a7a1-4f93-f7f8-8439826dad46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27748873851023215\n",
            "0.27570313328760265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-7de48b09b13c>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(output)\n"
          ]
        }
      ]
    }
  ]
}